# Logstash Pipeline Configuration for Agentic RAG System

input {
  # Beats input for Filebeat
  beats {
    port => 5044
  }
  
  # HTTP input for direct log shipping
  http {
    port => 5000
    codec => json
  }
  
  # TCP input for structured logs
  tcp {
    port => 5001
    codec => json_lines
  }
  
  # UDP input for high-volume logs
  udp {
    port => 5002
    codec => json
  }
}

filter {
  # Parse timestamp if it exists
  if [@timestamp] {
    date {
      match => [ "@timestamp", "ISO8601" ]
    }
  }
  
  # Add processing timestamp
  mutate {
    add_field => { "processed_at" => "%{+YYYY-MM-dd'T'HH:mm:ss.SSSZ}" }
  }
  
  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }
  
  # Extract log level
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  } else if [log_level] {
    mutate {
      add_field => { "level" => "%{log_level}" }
      uppercase => [ "level" ]
    }
  }
  
  # Normalize service name
  if [service] {
    mutate {
      lowercase => [ "service" ]
    }
  } else if [service_name] {
    mutate {
      add_field => { "service" => "%{service_name}" }
      lowercase => [ "service" ]
    }
  }
  
  # Extract tenant information
  if [tenant_id] {
    mutate {
      add_field => { "tenant" => "%{tenant_id}" }
    }
  }
  
  # Extract request information
  if [request_id] {
    mutate {
      add_field => { "request" => "%{request_id}" }
    }
  }
  
  # Extract trace information
  if [trace_id] {
    mutate {
      add_field => { "trace" => "%{trace_id}" }
    }
  }
  
  # Parse error information
  if [error] {
    if [error] =~ /^\{.*\}$/ {
      json {
        source => "error"
        target => "error_details"
      }
    }
  }
  
  # Add environment information
  mutate {
    add_field => { "environment" => "${ENVIRONMENT:development}" }
    add_field => { "cluster" => "agentic-rag" }
  }
  
  # Parse HTTP logs
  if [http] {
    if [http][method] {
      mutate {
        add_field => { "http_method" => "%{[http][method]}" }
      }
    }
    if [http][status_code] {
      mutate {
        add_field => { "http_status" => "%{[http][status_code]}" }
      }
    }
    if [http][url] {
      mutate {
        add_field => { "http_url" => "%{[http][url]}" }
      }
    }
  }
  
  # Parse database logs
  if [db] {
    if [db][query] {
      mutate {
        add_field => { "db_query" => "%{[db][query]}" }
      }
    }
    if [db][duration] {
      mutate {
        add_field => { "db_duration" => "%{[db][duration]}" }
      }
    }
  }
  
  # Grok patterns for unstructured logs
  if ![level] and [message] {
    grok {
      match => { 
        "message" => [
          "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:log_message}",
          "%{LOGLEVEL:level}: %{GREEDYDATA:log_message}",
          "\[%{TIMESTAMP_ISO8601:timestamp}\] %{LOGLEVEL:level}: %{GREEDYDATA:log_message}"
        ]
      }
    }
  }
  
  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "input", "log" ]
  }
  
  # Add tags based on content
  if [level] == "ERROR" {
    mutate {
      add_tag => [ "error" ]
    }
  }
  
  if [level] == "WARN" or [level] == "WARNING" {
    mutate {
      add_tag => [ "warning" ]
    }
  }
  
  if [message] =~ /(?i)exception|error|fail/ {
    mutate {
      add_tag => [ "exception" ]
    }
  }
  
  if [message] =~ /(?i)timeout|slow|performance/ {
    mutate {
      add_tag => [ "performance" ]
    }
  }
  
  if [message] =~ /(?i)auth|login|permission/ {
    mutate {
      add_tag => [ "security" ]
    }
  }
}

output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "agentic-rag-logs-%{+YYYY.MM.dd}"
    template_name => "agentic-rag-logs"
    template_pattern => "agentic-rag-logs-*"
    template => "/usr/share/logstash/templates/agentic-rag-template.json"
    template_overwrite => true
  }
  
  # Debug output (remove in production)
  if [level] == "DEBUG" {
    stdout {
      codec => rubydebug
    }
  }
  
  # Error output for failed parsing
  if "_grokparsefailure" in [tags] {
    file {
      path => "/usr/share/logstash/logs/grok_failures.log"
      codec => json_lines
    }
  }
}
